{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import zeros\n",
    "from numpy import ones\n",
    "from numpy import expand_dims\n",
    "from numpy import hstack\n",
    "from numpy.random import randn\n",
    "from numpy.random import randint\n",
    "from keras.datasets.mnist import load_data\n",
    "from keras.optimizers import Adam\n",
    "from keras.initializers import RandomNormal\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Model\n",
    "from keras import layers\n",
    "import tensorflow_datasets as tfds\n",
    "import tensorflow as tf\n",
    "from matplotlib import pyplot\n",
    "\n",
    "class InfoGAN:\n",
    "    def __init__(self):\n",
    "        \n",
    "        # number of values for the categorical control code\n",
    "        self.n_cat = 10\n",
    "        # size of the latent space\n",
    "        self.latent_dim = 62\n",
    "        #Define size of generator input\n",
    "        self.gen_input_size = self.latent_dim + self.n_cat\n",
    "        self.batch_size=32\n",
    "        self.kernel_init = RandomNormal(stddev=0.02)\n",
    "\n",
    "    def normalize_img(self,image,label):\n",
    "        label=1\n",
    "        return tf.cast(image, tf.float32) / 255.,label\n",
    "         \n",
    "    def load_MNIST(self):\n",
    "        ds, ds_info = tfds.load('mnist', split='train', with_info=True,as_supervised=True)\n",
    "        shape=ds_info.features['image'].shape\n",
    "        ds = ds.map(self.normalize_img, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "        ds = ds.cache()\n",
    "        # For true randomness, we set the shuffle buffer to the full dataset size.\n",
    "        ds = ds.shuffle(ds_info.splits['train'].num_examples)\n",
    "        # Batch after shuffling to get unique batches at each epoch.\n",
    "        ds = ds.batch(self.batch_size)\n",
    "        ds = ds.prefetch(tf.data.experimental.AUTOTUNE)\n",
    "        return ds,ds_info, shape\n",
    "    \n",
    "    def load_SVHN(self):\n",
    "        ds, ds_info = tfds.load('svhn_cropped', split='train', with_info=True,as_supervised=True)\n",
    "        shape=ds_info.features['image'].shape\n",
    "        ds = ds.map(self.normalize_img, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "        ds = ds.cache()\n",
    "        # For true randomness, we set the shuffle buffer to the full dataset size.\n",
    "        ds = ds.shuffle(ds_info.splits['train'].num_examples)\n",
    "        # Batch after shuffling to get unique batches at each epoch.\n",
    "        ds = ds.batch(self.batch_size)\n",
    "        ds = ds.prefetch(tf.data.experimental.AUTOTUNE)\n",
    "        return ds,ds_info, shape\n",
    "    \n",
    "    def load_CELEBA(self):\n",
    "        #To Do, access via tensorflow datasets seems to be broken due to the ds being hosted on Drive\n",
    "        pass\n",
    "\n",
    "    def show_real_examples(self,ds, ds_info):\n",
    "        fig = tfds.show_examples(ds, ds_info)\n",
    "\n",
    "    #Define the generator model:\n",
    "    def get_generator(self,shape):\n",
    "        input_latent = layers.Input(shape=(self.gen_input_size))\n",
    "        \n",
    "        #The various datasets have various sizes and #channels so the dimension of the generator needs to be variable\n",
    "        res=int(shape[0]/4)\n",
    "        depth=int(shape[-1])\n",
    "        \n",
    "        n_nodes = 128 * res * res\n",
    "\n",
    "        g = layers.Dense(n_nodes)(input_latent)\n",
    "        g = layers.ReLU()(g)\n",
    "        g = layers.BatchNormalization()(g)\n",
    "        g = layers.Reshape((res, res, 128))(g)\n",
    "\n",
    "        g = layers.Conv2D(64, 4, padding='same',activation='relu',kernel_initializer=self.kernel_init)(g)\n",
    "        g = layers.ReLU()(g)\n",
    "        g = layers.BatchNormalization()(g)\n",
    "\n",
    "        g = layers.Conv2DTranspose(32, 4, strides=(2,2), padding='same',kernel_initializer=self.kernel_init)(g)\n",
    "        g = layers.ReLU()(g)\n",
    "        g = layers.BatchNormalization()(g)\n",
    "        g = layers.Conv2DTranspose(depth, 4, strides=(2,2), padding='same',kernel_initializer=self.kernel_init)(g)\n",
    "        # Sigmoid output\n",
    "        output_layer = layers.Activation('sigmoid')(g)\n",
    "        # define the generator model\n",
    "        gen_model = Model(input_latent, output_layer)\n",
    "        return gen_model\n",
    "    \n",
    "    \n",
    "    def get_discr_q(self,input_shape):\n",
    "        input_image=layers.Input(shape=input_shape)\n",
    "\n",
    "        l=layers.Conv2D(32, 4, strides=(2,2),padding='same',kernel_initializer=self.kernel_init)(input_image)\n",
    "        l=layers.ReLU()(l)\n",
    "\n",
    "        l=layers.Conv2D(64, 4, strides=(2,2), padding='same',kernel_initializer=self.kernel_init)(l)\n",
    "        l=layers.ReLU()(l)\n",
    "        l=layers.BatchNormalization()(l)\n",
    "\n",
    "        l=layers.Conv2D(128, 4, strides=(2,2), padding='same',kernel_initializer=self.kernel_init)(l)\n",
    "        l=layers.ReLU()(l)\n",
    "        l=layers.BatchNormalization()(l)\n",
    "\n",
    "        l=layers.Flatten()(l)\n",
    "        #Classification head of the discriminator\n",
    "        out=layers.Dense(1,activation='sigmoid')(l)\n",
    "        discr_model = Model(input_image, out)\n",
    "        discr_model.compile(loss='binary_crossentropy', optimizer=Adam(lr=0.0002, beta_1=0.5))\n",
    "        # create q model layers\n",
    "        q = layers.Dense(128)(l)\n",
    "        q = layers.BatchNormalization()(q)\n",
    "        q = layers.LeakyReLU(alpha=0.1)(q)\n",
    "        # q model output\n",
    "        out_codes = layers.Dense(self.n_cat, activation='softmax')(q)\n",
    "        # define q model\n",
    "        q_model = Model(input_image, out_codes)\n",
    "        return discr_model, q_model\n",
    "    \n",
    "    def infogan(self,gen_model, discr_model, q_model):\n",
    "        # make weights in the discriminator (some shared with the q model) as not trainable\n",
    "        for layer in discr_model.layers:\n",
    "            if not isinstance(layer, layers.BatchNormalization):\n",
    "                layer.trainable = False\n",
    "        # connect g outputs to d inputs\n",
    "        discr_output = discr_model(gen_model.output)\n",
    "        # connect g outputs to q inputs\n",
    "        q_output = q_model(gen_model.output)\n",
    "        # define composite model\n",
    "        infogan_model = Model(gen_model.input, [discr_output, q_output])\n",
    "        # compile model\n",
    "        opt = Adam(lr=0.0002, beta_1=0.5)\n",
    "        infogan_model.compile(loss=['binary_crossentropy', 'categorical_crossentropy'], optimizer=opt)\n",
    "        return infogan_model\n",
    "    \n",
    "\n",
    "    # generate points in latent space as input for the generator\n",
    "    def generate_noise(self, n_samples):\n",
    "        # generate points in the latent space\n",
    "        z_latent=randn(n_samples,self.latent_dim)\n",
    "        # generate categorical one-hot codes\n",
    "        cat_codes=np.eye(self.n_cat)[np.random.choice(self.n_cat, n_samples)]\n",
    "        # concatenate latent points and control codes\n",
    "        z_input = hstack((z_latent, cat_codes))\n",
    "        return [z_input, cat_codes]\n",
    "    \n",
    "    # use the generator to generate n fake examples, with class labels\n",
    "    def generate_fake_samples(self,generator, n_samples):\n",
    "        # generate points in latent space and control codes\n",
    "        z_input, _ = self.generate_noise(n_samples)\n",
    "        # predict outputs\n",
    "        images = generator.predict(z_input)\n",
    "        # create class labels\n",
    "        y = zeros((n_samples, 1))\n",
    "        return images, y\n",
    "    \n",
    "    def summarize_performance(self,step, gen_model, gan_model, n_samples=100):\n",
    "        # prepare fake examples\n",
    "        X, _ = self.generate_fake_samples(gen_model, n_samples)\n",
    "\n",
    "        # plot images\n",
    "        for i in range(n_samples):\n",
    "            # define subplot\n",
    "            pyplot.subplot(10, 10, 1 + i)\n",
    "            # turn off axis\n",
    "            pyplot.axis('off')\n",
    "            # plot raw pixel data\n",
    "            #pyplot.imshow(X[i, :, :, 0], cmap='gray_r')\n",
    "            pyplot.imshow(X[i, :, :, :])\n",
    "        # save plot to file\n",
    "        filename1 = 'generated_plot_%04d.png' % (step+1)\n",
    "        pyplot.savefig(filename1)\n",
    "        pyplot.close()\n",
    "        # save the generator model\n",
    "        filename2 = 'model_%04d.h5' % (step+1)\n",
    "        gen_model.save(filename2)\n",
    "        # save the gan model\n",
    "        filename3 = 'gan_model_%04d.h5' % (step+1)\n",
    "        gan_model.save(filename3)\n",
    "        print('>Saved: %s, %s, and %s' % (filename1, filename2, filename3))\n",
    "        \n",
    "    # train the generator and discriminator\n",
    "    def train(self,gen_model, discr_model, infogan_model, dataset, n_epochs=100):\n",
    "        # calculate the number of batches per training epoch\n",
    "        bat_per_epo = len(ds)\n",
    "        # calculate the number of training iterations\n",
    "        n_steps = bat_per_epo * n_epochs\n",
    "        print(n_steps)\n",
    "        # manually enumerate epochs\n",
    "        for i in range(n_steps):\n",
    "            # update discriminator and q model weights\n",
    "            d_loss1 = discr_model.fit(ds,steps_per_epoch=1,verbose=0)\n",
    "            # generate 'fake' examples\n",
    "            X_fake, y_fake = self.generate_fake_samples(gen_model, self.batch_size)\n",
    "            # update discriminator model weights\n",
    "            d_loss2 = discr_model.fit(X_fake, y_fake,verbose=0,batch_size=self.batch_size)\n",
    "            # prepare points in latent space as input for the generator\n",
    "            z_input, cat_codes = self.generate_noise(self.batch_size)\n",
    "            # create inverted labels for the fake samples\n",
    "            y_gan = ones((self.batch_size, 1))\n",
    "            # update the g via the d and q error\n",
    "            gan_loss = infogan_model.fit(z_input, [y_gan, cat_codes],verbose=0,batch_size=self.batch_size)\n",
    "            # summarize loss on this batch\n",
    "            print('>%d, d[%.3f,%.3f], g[%.3f] q[%.3f]' % (i+1, d_loss1.history['loss'][0], d_loss2.history['loss'][0], list(gan_loss.history.items())[1][1][0],list(gan_loss.history.items())[2][1][0]))\n",
    "            # evaluate the model performance every 'epoch'\n",
    "            if (i+1) % (bat_per_epo * 10) == 0:\n",
    "                self.summarize_performance(i, gen_model, infogan_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "gan=InfoGAN()\n",
    "ds,ds_info, shape=gan.load_SVHN()\n",
    "gen_model=gan.get_generator(shape)\n",
    "discr_model,q_model=gan.get_discr_q(shape)\n",
    "infogan_model=gan.infogan(gen_model, discr_model, q_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2290\n",
      ">1, d[0.364,1.022], g[0.948] q[0.160]\n",
      ">2, d[0.307,0.542], g[1.481] q[0.056]\n",
      ">3, d[0.789,0.516], g[1.059] q[0.158]\n",
      ">4, d[0.495,0.699], g[1.445] q[0.163]\n",
      ">5, d[0.439,0.639], g[1.404] q[0.161]\n",
      ">6, d[0.671,0.637], g[1.319] q[0.089]\n",
      ">7, d[0.482,0.452], g[1.412] q[0.173]\n",
      ">8, d[0.652,0.526], g[1.441] q[0.052]\n",
      ">9, d[0.382,0.464], g[1.440] q[0.071]\n",
      ">10, d[0.573,0.475], g[1.268] q[0.094]\n",
      ">11, d[0.452,0.535], g[1.403] q[0.066]\n",
      ">12, d[0.539,0.511], g[1.358] q[0.110]\n",
      ">13, d[0.668,0.450], g[1.189] q[0.190]\n",
      ">14, d[0.416,0.540], g[1.334] q[0.055]\n",
      ">15, d[0.778,0.839], g[1.294] q[0.145]\n",
      ">16, d[0.722,0.774], g[1.187] q[0.500]\n",
      ">17, d[0.356,0.498], g[1.388] q[0.210]\n",
      ">18, d[0.507,0.399], g[1.665] q[0.080]\n",
      ">19, d[0.874,0.543], g[1.126] q[0.076]\n",
      ">20, d[0.454,0.506], g[1.514] q[0.118]\n",
      ">21, d[0.264,0.420], g[1.208] q[0.082]\n",
      ">22, d[0.776,0.659], g[1.225] q[0.125]\n",
      ">23, d[0.360,0.452], g[1.078] q[0.141]\n",
      ">24, d[0.881,0.597], g[1.220] q[0.060]\n",
      ">25, d[0.675,0.768], g[1.314] q[0.081]\n",
      ">26, d[0.811,1.029], g[0.988] q[0.066]\n",
      ">27, d[0.677,0.687], g[0.817] q[0.092]\n",
      ">28, d[0.297,0.588], g[1.549] q[0.106]\n",
      ">29, d[0.767,0.423], g[1.455] q[0.075]\n",
      ">30, d[0.451,0.643], g[1.685] q[0.248]\n",
      ">31, d[0.716,0.720], g[1.456] q[0.145]\n",
      ">32, d[0.643,0.525], g[1.056] q[0.308]\n",
      ">33, d[0.767,0.606], g[1.074] q[0.105]\n",
      ">34, d[0.596,0.920], g[1.155] q[0.151]\n",
      ">35, d[0.548,0.623], g[1.473] q[0.090]\n",
      ">36, d[0.683,0.575], g[1.141] q[0.092]\n",
      ">37, d[0.549,0.573], g[1.050] q[0.214]\n",
      ">38, d[0.333,0.587], g[1.480] q[0.175]\n",
      ">39, d[0.611,0.529], g[1.414] q[0.092]\n",
      ">40, d[0.538,0.567], g[1.110] q[0.083]\n",
      ">41, d[0.645,0.526], g[1.202] q[0.183]\n",
      ">42, d[0.424,0.550], g[1.530] q[0.077]\n",
      ">43, d[0.611,0.543], g[1.395] q[0.066]\n",
      ">44, d[0.369,0.599], g[1.413] q[0.048]\n",
      ">45, d[0.649,0.511], g[1.439] q[0.128]\n",
      ">46, d[0.520,0.621], g[1.406] q[0.057]\n",
      ">47, d[0.471,0.480], g[1.146] q[0.099]\n",
      ">48, d[0.585,0.587], g[1.271] q[0.140]\n",
      ">49, d[0.464,0.600], g[1.401] q[0.187]\n",
      ">50, d[0.515,0.407], g[1.157] q[0.119]\n",
      ">51, d[0.431,0.663], g[1.426] q[0.075]\n",
      ">52, d[0.370,0.538], g[1.860] q[0.084]\n",
      ">53, d[0.963,0.552], g[1.119] q[0.074]\n",
      ">54, d[0.473,0.529], g[2.725] q[0.304]\n",
      ">55, d[2.366,0.897], g[1.265] q[0.174]\n",
      ">56, d[0.894,0.770], g[0.918] q[0.119]\n",
      ">57, d[0.540,1.043], g[0.648] q[0.196]\n",
      ">58, d[0.448,0.500], g[1.224] q[0.072]\n",
      ">59, d[0.595,0.577], g[1.119] q[0.393]\n",
      ">60, d[0.658,0.753], g[0.980] q[0.241]\n",
      ">61, d[0.339,0.759], g[1.503] q[0.065]\n",
      ">62, d[1.083,0.541], g[1.262] q[0.271]\n",
      ">63, d[0.857,0.853], g[1.269] q[0.163]\n",
      ">64, d[0.817,0.867], g[1.021] q[0.108]\n",
      ">65, d[0.472,0.668], g[1.144] q[0.257]\n",
      ">66, d[0.679,0.572], g[1.032] q[0.150]\n",
      ">67, d[0.473,0.869], g[1.034] q[0.345]\n",
      ">68, d[1.096,0.520], g[1.162] q[0.087]\n",
      ">69, d[0.541,0.787], g[1.232] q[0.129]\n",
      ">70, d[0.713,0.606], g[1.352] q[0.063]\n",
      ">71, d[0.833,0.793], g[0.973] q[0.103]\n",
      ">72, d[0.570,0.750], g[1.277] q[0.120]\n",
      ">73, d[0.647,0.600], g[1.150] q[0.097]\n",
      ">74, d[0.701,0.563], g[1.184] q[0.071]\n",
      ">75, d[0.413,0.767], g[1.069] q[0.108]\n",
      ">76, d[0.782,0.733], g[1.092] q[0.074]\n",
      ">77, d[0.589,0.604], g[1.330] q[0.128]\n",
      ">78, d[0.626,0.635], g[0.989] q[0.099]\n",
      ">79, d[0.477,0.572], g[1.069] q[0.121]\n",
      ">80, d[0.535,0.607], g[1.029] q[0.089]\n",
      ">81, d[0.846,0.622], g[1.235] q[0.063]\n",
      ">82, d[0.582,0.503], g[1.449] q[0.095]\n",
      ">83, d[0.670,0.544], g[1.305] q[0.084]\n",
      ">84, d[0.617,0.509], g[1.219] q[0.021]\n",
      ">85, d[0.653,0.652], g[1.032] q[0.152]\n",
      ">86, d[0.470,0.555], g[1.173] q[0.084]\n",
      ">87, d[0.630,0.595], g[1.133] q[0.032]\n",
      ">88, d[0.310,0.480], g[1.465] q[0.032]\n",
      ">89, d[0.593,0.439], g[1.301] q[0.057]\n",
      ">90, d[0.370,0.464], g[1.440] q[0.047]\n",
      ">91, d[0.579,0.455], g[1.424] q[0.159]\n",
      ">92, d[0.594,0.605], g[1.339] q[0.062]\n",
      ">93, d[0.666,0.521], g[1.441] q[0.038]\n",
      ">94, d[0.447,0.668], g[1.483] q[0.075]\n",
      ">95, d[0.690,0.599], g[1.180] q[0.059]\n",
      ">96, d[0.370,0.523], g[1.523] q[0.107]\n",
      ">97, d[0.758,0.552], g[1.358] q[0.128]\n",
      ">98, d[0.334,0.426], g[1.198] q[0.121]\n",
      ">99, d[0.742,1.050], g[1.208] q[0.065]\n",
      ">100, d[0.508,0.490], g[1.403] q[0.040]\n",
      ">101, d[0.730,0.719], g[1.231] q[0.070]\n",
      ">102, d[0.519,0.764], g[1.221] q[0.198]\n",
      ">103, d[0.307,0.454], g[1.506] q[0.062]\n",
      ">104, d[0.457,0.358], g[1.709] q[0.132]\n",
      ">105, d[0.613,0.577], g[1.529] q[0.052]\n",
      ">106, d[0.706,0.541], g[1.298] q[0.054]\n",
      ">107, d[0.653,0.665], g[1.304] q[0.041]\n",
      ">108, d[0.710,0.873], g[1.111] q[0.118]\n",
      ">109, d[0.432,0.681], g[1.135] q[0.083]\n",
      ">110, d[0.779,0.639], g[1.131] q[0.098]\n",
      ">111, d[0.614,0.622], g[1.275] q[0.131]\n",
      ">112, d[0.509,0.511], g[1.083] q[0.061]\n",
      ">113, d[0.528,0.445], g[1.250] q[0.092]\n",
      ">114, d[0.506,0.627], g[1.407] q[0.068]\n",
      ">115, d[0.595,0.590], g[1.160] q[0.208]\n",
      ">116, d[0.463,0.637], g[1.316] q[0.107]\n",
      ">117, d[0.663,0.536], g[1.386] q[0.204]\n",
      ">118, d[0.477,0.651], g[1.398] q[0.104]\n",
      ">119, d[0.624,0.544], g[1.211] q[0.086]\n",
      ">120, d[0.544,0.694], g[1.496] q[0.057]\n",
      ">121, d[0.693,0.496], g[1.060] q[0.128]\n",
      ">122, d[0.521,0.613], g[1.253] q[0.109]\n",
      ">123, d[0.347,0.469], g[1.546] q[0.048]\n",
      ">124, d[0.445,0.368], g[1.244] q[0.068]\n",
      ">125, d[0.668,0.477], g[1.288] q[0.157]\n",
      ">126, d[0.516,0.523], g[1.323] q[0.101]\n",
      ">127, d[0.744,0.587], g[1.252] q[0.052]\n",
      ">128, d[0.490,0.481], g[0.781] q[0.193]\n",
      ">129, d[0.524,0.811], g[1.113] q[0.036]\n",
      ">130, d[0.581,0.801], g[1.645] q[0.076]\n",
      ">131, d[0.395,0.400], g[1.668] q[0.043]\n",
      ">132, d[0.540,0.457], g[1.636] q[0.096]\n",
      ">133, d[0.692,0.689], g[1.357] q[0.142]\n",
      ">134, d[0.702,0.622], g[0.914] q[0.355]\n",
      ">135, d[0.577,0.604], g[1.048] q[0.054]\n",
      ">136, d[0.694,0.485], g[1.297] q[0.111]\n",
      ">137, d[0.582,0.550], g[1.299] q[0.081]\n",
      ">138, d[0.444,0.605], g[1.187] q[0.053]\n",
      ">139, d[0.608,0.465], g[1.324] q[0.276]\n",
      ">140, d[0.642,0.559], g[1.342] q[0.075]\n",
      ">141, d[0.518,0.455], g[1.309] q[0.059]\n",
      ">142, d[0.604,0.791], g[1.317] q[0.024]\n",
      ">143, d[0.674,0.655], g[1.405] q[0.064]\n",
      ">144, d[0.360,0.360], g[1.316] q[0.078]\n",
      ">145, d[0.724,0.467], g[1.325] q[0.086]\n",
      ">146, d[0.235,0.641], g[1.766] q[0.027]\n",
      ">147, d[0.739,0.521], g[1.273] q[0.088]\n",
      ">148, d[0.855,0.863], g[1.351] q[0.033]\n",
      ">149, d[0.682,0.685], g[1.337] q[0.053]\n",
      ">150, d[0.313,0.475], g[1.580] q[0.086]\n",
      ">151, d[0.758,0.450], g[1.463] q[0.066]\n",
      ">152, d[0.724,0.587], g[1.202] q[0.062]\n",
      ">153, d[0.707,0.839], g[1.365] q[0.080]\n",
      ">154, d[0.568,0.590], g[1.197] q[0.058]\n",
      ">155, d[0.659,0.623], g[1.462] q[0.061]\n",
      ">156, d[0.345,0.496], g[1.388] q[0.055]\n",
      ">157, d[0.500,0.477], g[1.333] q[0.060]\n",
      ">158, d[0.577,0.817], g[1.379] q[0.071]\n",
      ">159, d[0.644,0.579], g[1.432] q[0.091]\n",
      ">160, d[0.439,0.428], g[1.477] q[0.046]\n",
      ">161, d[0.767,0.529], g[1.415] q[0.056]\n",
      ">162, d[0.336,0.596], g[1.228] q[0.036]\n",
      ">163, d[0.619,0.520], g[1.349] q[0.166]\n",
      ">164, d[0.764,0.505], g[0.987] q[0.149]\n",
      ">165, d[0.364,0.567], g[1.264] q[0.078]\n",
      ">166, d[0.803,0.446], g[1.055] q[0.056]\n",
      ">167, d[0.585,0.609], g[1.188] q[0.030]\n",
      ">168, d[0.512,0.656], g[1.274] q[0.037]\n",
      ">169, d[0.316,0.713], g[1.310] q[0.063]\n",
      ">170, d[1.231,0.419], g[1.379] q[0.209]\n",
      ">171, d[0.725,0.649], g[1.081] q[0.117]\n",
      ">172, d[0.459,0.702], g[1.089] q[0.037]\n",
      ">173, d[0.642,0.619], g[1.123] q[0.042]\n",
      ">174, d[0.388,0.529], g[1.395] q[0.060]\n",
      ">175, d[0.316,0.461], g[1.542] q[0.110]\n",
      ">176, d[0.762,0.589], g[1.455] q[0.072]\n",
      ">177, d[0.596,0.429], g[1.156] q[0.099]\n",
      ">178, d[0.502,0.466], g[1.269] q[0.112]\n",
      ">179, d[0.384,0.687], g[1.349] q[0.056]\n",
      ">180, d[0.448,0.495], g[1.427] q[0.085]\n",
      ">181, d[0.583,0.465], g[1.443] q[0.063]\n",
      ">182, d[0.619,0.659], g[1.296] q[0.046]\n",
      ">183, d[0.357,0.585], g[1.508] q[0.100]\n",
      ">184, d[0.358,0.396], g[1.432] q[0.021]\n",
      ">185, d[0.943,0.551], g[1.371] q[0.069]\n",
      ">186, d[0.746,0.785], g[1.181] q[0.091]\n",
      ">187, d[0.611,0.670], g[1.413] q[0.040]\n",
      ">188, d[0.587,0.589], g[1.753] q[0.054]\n",
      ">189, d[0.586,0.449], g[1.451] q[0.182]\n",
      ">190, d[0.744,0.535], g[1.207] q[0.041]\n",
      ">191, d[0.677,0.731], g[1.139] q[0.117]\n",
      ">192, d[0.529,0.543], g[1.275] q[0.135]\n",
      ">193, d[0.303,0.778], g[1.404] q[0.057]\n",
      ">194, d[0.464,0.392], g[1.512] q[0.104]\n",
      ">195, d[0.946,0.552], g[1.079] q[0.096]\n",
      ">196, d[0.700,0.588], g[1.092] q[0.064]\n",
      ">197, d[0.592,0.721], g[1.065] q[0.039]\n",
      ">198, d[0.350,0.514], g[1.290] q[0.017]\n",
      ">199, d[0.518,0.608], g[1.485] q[0.059]\n",
      ">200, d[0.280,0.421], g[1.551] q[0.082]\n",
      ">201, d[0.948,0.591], g[1.463] q[0.028]\n",
      ">202, d[0.766,0.720], g[1.300] q[0.259]\n",
      ">203, d[0.344,0.499], g[1.575] q[0.111]\n",
      ">204, d[0.850,0.485], g[1.548] q[0.027]\n",
      ">205, d[0.403,0.487], g[1.347] q[0.034]\n",
      ">206, d[0.293,0.372], g[1.464] q[0.107]\n",
      ">207, d[1.091,0.842], g[1.037] q[0.227]\n",
      ">208, d[0.412,0.739], g[1.474] q[0.209]\n",
      ">209, d[0.476,1.118], g[1.339] q[0.146]\n",
      ">210, d[0.918,0.373], g[1.780] q[0.059]\n",
      ">211, d[1.110,0.967], g[1.100] q[0.086]\n",
      ">212, d[0.340,0.451], g[1.282] q[0.290]\n",
      ">213, d[0.761,0.559], g[1.394] q[0.314]\n",
      ">214, d[0.486,0.467], g[0.967] q[0.295]\n",
      ">215, d[0.629,0.514], g[1.121] q[0.078]\n",
      ">216, d[0.412,0.618], g[1.205] q[0.043]\n",
      ">217, d[0.416,0.582], g[1.091] q[0.154]\n",
      ">218, d[0.599,0.662], g[1.437] q[0.060]\n",
      ">219, d[0.685,0.564], g[1.404] q[0.301]\n",
      ">220, d[0.412,0.423], g[1.207] q[0.069]\n",
      ">221, d[0.655,0.441], g[1.186] q[0.072]\n",
      ">222, d[0.551,0.587], g[1.120] q[0.162]\n",
      ">223, d[0.586,0.641], g[1.419] q[0.113]\n",
      ">224, d[0.735,0.535], g[1.283] q[0.088]\n",
      ">225, d[0.430,0.497], g[1.387] q[0.063]\n",
      ">226, d[0.502,0.597], g[1.309] q[0.037]\n",
      ">227, d[0.921,0.609], g[1.039] q[0.035]\n",
      ">228, d[0.530,0.640], g[0.821] q[0.045]\n",
      ">229, d[0.690,0.645], g[1.063] q[0.101]\n",
      ">230, d[0.568,0.724], g[0.956] q[0.222]\n",
      ">231, d[0.495,0.967], g[0.961] q[0.054]\n",
      ">232, d[0.624,0.640], g[1.443] q[0.387]\n",
      ">233, d[1.073,0.563], g[1.113] q[0.166]\n",
      ">234, d[0.343,0.512], g[1.366] q[0.104]\n",
      ">235, d[0.442,0.731], g[1.440] q[0.078]\n",
      ">236, d[0.683,0.470], g[1.391] q[0.021]\n",
      ">237, d[0.498,0.468], g[1.356] q[0.046]\n",
      ">238, d[0.423,0.500], g[1.221] q[0.048]\n",
      ">239, d[0.483,0.576], g[1.173] q[0.125]\n",
      ">240, d[0.500,0.503], g[1.467] q[0.098]\n",
      ">241, d[0.651,0.623], g[1.180] q[0.022]\n",
      ">242, d[0.366,0.594], g[1.369] q[0.109]\n",
      ">243, d[0.572,0.589], g[1.207] q[0.137]\n",
      ">244, d[0.693,0.579], g[1.258] q[0.069]\n",
      ">245, d[0.731,0.561], g[1.173] q[0.056]\n",
      ">246, d[0.628,0.532], g[1.245] q[0.020]\n",
      ">247, d[0.343,0.529], g[1.175] q[0.037]\n",
      ">248, d[0.287,0.393], g[1.690] q[0.043]\n",
      ">249, d[0.591,0.561], g[1.162] q[0.129]\n",
      ">250, d[0.961,0.652], g[0.969] q[0.093]\n",
      ">251, d[0.658,0.561], g[1.055] q[0.121]\n",
      ">252, d[0.365,0.521], g[1.302] q[0.086]\n",
      ">253, d[0.463,0.553], g[1.126] q[0.076]\n",
      ">254, d[0.640,0.565], g[1.092] q[0.079]\n",
      ">255, d[0.358,0.792], g[1.291] q[0.206]\n",
      ">256, d[0.912,0.530], g[1.274] q[0.137]\n",
      ">257, d[0.556,0.570], g[1.326] q[0.119]\n",
      ">258, d[0.899,0.540], g[1.278] q[0.074]\n",
      ">259, d[0.270,0.508], g[1.599] q[0.088]\n",
      ">260, d[0.624,0.420], g[1.474] q[0.191]\n",
      ">261, d[0.736,0.614], g[1.418] q[0.096]\n",
      ">262, d[0.495,0.352], g[1.414] q[0.100]\n",
      ">263, d[0.697,0.548], g[1.356] q[0.146]\n",
      ">264, d[0.365,0.470], g[1.196] q[0.245]\n",
      ">265, d[0.329,1.775], g[1.887] q[0.120]\n",
      ">266, d[0.792,0.271], g[1.868] q[0.270]\n",
      ">267, d[0.608,0.368], g[1.518] q[0.120]\n",
      ">268, d[0.921,0.578], g[1.117] q[0.060]\n",
      ">269, d[0.348,0.544], g[1.313] q[0.045]\n",
      ">270, d[0.316,0.489], g[1.398] q[0.086]\n",
      ">271, d[0.769,0.489], g[1.303] q[0.135]\n",
      ">272, d[0.399,0.910], g[1.645] q[0.102]\n",
      ">273, d[0.253,0.392], g[1.840] q[0.092]\n",
      ">274, d[0.968,0.545], g[1.397] q[0.025]\n",
      ">275, d[0.996,0.596], g[1.146] q[0.071]\n",
      ">276, d[0.469,0.690], g[0.897] q[0.058]\n",
      ">277, d[0.859,0.717], g[1.019] q[0.022]\n",
      ">278, d[0.613,0.775], g[1.238] q[0.086]\n",
      ">279, d[0.586,0.623], g[1.028] q[0.064]\n",
      ">280, d[0.608,0.625], g[1.293] q[0.039]\n",
      ">281, d[0.559,1.217], g[1.493] q[0.046]\n",
      ">282, d[0.988,0.744], g[1.262] q[0.050]\n",
      ">283, d[0.778,0.654], g[1.347] q[0.111]\n",
      ">284, d[0.427,0.440], g[1.237] q[0.104]\n",
      ">285, d[0.712,0.747], g[1.270] q[0.041]\n",
      ">286, d[0.675,0.597], g[1.247] q[0.186]\n",
      ">287, d[0.719,0.521], g[1.142] q[0.073]\n",
      ">288, d[0.505,0.627], g[1.112] q[0.132]\n",
      ">289, d[0.309,0.409], g[1.322] q[0.222]\n",
      ">290, d[0.748,0.463], g[1.282] q[0.170]\n",
      ">291, d[0.700,0.561], g[0.875] q[0.177]\n",
      ">292, d[0.210,0.662], g[1.433] q[0.106]\n",
      ">293, d[0.595,0.631], g[1.459] q[0.089]\n",
      ">294, d[0.825,0.848], g[1.401] q[0.314]\n",
      ">295, d[0.524,0.787], g[1.726] q[0.380]\n",
      ">296, d[0.503,0.756], g[1.865] q[0.117]\n",
      ">297, d[0.883,0.515], g[1.534] q[0.054]\n",
      ">298, d[0.851,0.637], g[1.711] q[0.663]\n",
      ">299, d[0.733,0.550], g[1.313] q[0.175]\n",
      ">300, d[0.701,0.841], g[1.499] q[0.280]\n",
      ">301, d[0.551,0.505], g[1.263] q[0.065]\n",
      ">302, d[0.614,0.590], g[1.238] q[0.153]\n",
      ">303, d[0.389,0.837], g[1.676] q[0.230]\n",
      ">304, d[0.734,0.587], g[1.245] q[0.101]\n",
      ">305, d[0.436,0.573], g[1.563] q[0.197]\n",
      ">306, d[0.334,0.349], g[1.451] q[0.037]\n",
      ">307, d[0.410,0.309], g[1.078] q[0.084]\n",
      ">308, d[0.425,0.326], g[1.448] q[0.048]\n",
      ">309, d[0.651,0.686], g[1.388] q[0.110]\n",
      ">310, d[0.414,0.356], g[1.624] q[0.127]\n",
      ">311, d[0.706,0.587], g[1.008] q[0.065]\n",
      ">312, d[0.805,1.058], g[1.012] q[0.063]\n",
      ">313, d[0.297,0.683], g[1.508] q[0.087]\n",
      ">314, d[0.864,0.403], g[1.403] q[0.040]\n",
      ">315, d[0.842,0.661], g[1.186] q[0.044]\n",
      ">316, d[0.500,0.697], g[1.082] q[0.032]\n",
      ">317, d[0.596,0.513], g[1.225] q[0.131]\n",
      ">318, d[0.625,0.404], g[1.062] q[0.078]\n",
      ">319, d[0.453,0.735], g[1.173] q[0.042]\n",
      ">320, d[0.519,0.539], g[1.093] q[0.038]\n",
      ">321, d[0.526,0.546], g[1.024] q[0.055]\n",
      ">322, d[0.625,0.695], g[0.933] q[0.017]\n",
      ">323, d[0.653,0.827], g[1.242] q[0.101]\n",
      ">324, d[0.529,0.551], g[1.284] q[0.022]\n",
      ">325, d[0.613,0.562], g[1.237] q[0.036]\n",
      ">326, d[0.307,0.513], g[1.395] q[0.075]\n",
      ">327, d[0.650,0.560], g[1.318] q[0.109]\n",
      ">328, d[0.831,0.594], g[0.874] q[0.157]\n",
      ">329, d[0.401,0.842], g[1.069] q[0.089]\n",
      ">330, d[0.659,0.642], g[1.176] q[0.105]\n",
      ">331, d[0.662,0.545], g[1.272] q[0.181]\n",
      ">332, d[0.785,0.568], g[1.370] q[0.074]\n",
      ">333, d[0.653,0.494], g[1.108] q[0.137]\n",
      ">334, d[0.711,0.589], g[0.890] q[0.261]\n",
      ">335, d[0.464,0.652], g[1.090] q[0.049]\n",
      ">336, d[0.414,0.486], g[1.223] q[0.034]\n",
      ">337, d[0.498,0.489], g[1.305] q[0.058]\n",
      ">338, d[0.539,0.583], g[1.229] q[0.051]\n",
      ">339, d[0.619,0.595], g[1.034] q[0.152]\n",
      ">340, d[0.775,0.842], g[0.854] q[0.171]\n",
      ">341, d[0.789,0.914], g[1.279] q[0.040]\n",
      ">342, d[0.578,0.435], g[1.544] q[0.086]\n",
      ">343, d[0.512,0.492], g[1.168] q[0.141]\n",
      ">344, d[0.527,0.424], g[1.151] q[0.114]\n",
      ">345, d[0.559,0.895], g[1.585] q[0.038]\n",
      ">346, d[0.824,0.492], g[1.339] q[0.035]\n",
      ">347, d[0.504,0.762], g[1.154] q[0.074]\n",
      ">348, d[0.554,0.738], g[1.125] q[0.131]\n",
      ">349, d[0.473,0.514], g[1.705] q[0.100]\n",
      ">350, d[0.988,0.478], g[1.096] q[0.098]\n",
      ">351, d[0.453,0.731], g[1.198] q[0.050]\n",
      ">352, d[0.383,0.450], g[1.214] q[0.107]\n",
      ">353, d[0.645,0.761], g[1.327] q[0.075]\n",
      ">354, d[0.668,0.852], g[1.441] q[0.081]\n",
      ">355, d[0.664,0.554], g[1.355] q[0.113]\n",
      ">356, d[0.734,0.494], g[1.138] q[0.125]\n",
      ">357, d[0.667,0.795], g[1.163] q[0.046]\n",
      ">358, d[0.399,0.576], g[1.299] q[0.033]\n",
      ">359, d[0.610,0.537], g[1.249] q[0.034]\n",
      ">360, d[0.420,0.479], g[1.334] q[0.046]\n",
      ">361, d[0.697,0.444], g[1.294] q[0.067]\n",
      ">362, d[0.763,0.708], g[1.185] q[0.056]\n",
      ">363, d[0.530,0.674], g[1.159] q[0.062]\n",
      ">364, d[0.661,0.741], g[1.410] q[0.075]\n",
      ">365, d[0.469,0.557], g[1.253] q[0.133]\n",
      ">366, d[0.626,0.716], g[1.334] q[0.068]\n",
      ">367, d[0.274,0.564], g[1.608] q[0.122]\n",
      ">368, d[1.179,0.534], g[1.202] q[0.050]\n",
      ">369, d[0.736,0.681], g[1.121] q[0.078]\n",
      ">370, d[0.465,0.824], g[1.200] q[0.231]\n",
      ">371, d[0.343,0.465], g[1.297] q[0.065]\n",
      ">372, d[0.417,0.449], g[1.422] q[0.122]\n",
      ">373, d[0.648,0.614], g[1.140] q[0.093]\n",
      ">374, d[0.579,0.614], g[1.426] q[0.048]\n",
      ">375, d[0.628,0.499], g[1.214] q[0.064]\n",
      ">376, d[0.381,0.458], g[1.371] q[0.130]\n",
      ">377, d[0.384,0.630], g[1.464] q[0.078]\n",
      ">378, d[0.717,0.430], g[1.058] q[0.051]\n",
      ">379, d[0.449,0.506], g[1.012] q[0.111]\n",
      ">380, d[0.817,0.614], g[0.962] q[0.104]\n",
      ">381, d[0.620,0.980], g[1.071] q[0.056]\n",
      ">382, d[0.557,0.933], g[1.166] q[0.144]\n",
      ">383, d[0.807,0.690], g[1.303] q[0.139]\n",
      ">384, d[0.671,0.900], g[1.699] q[0.065]\n",
      ">385, d[0.831,0.794], g[1.309] q[0.058]\n",
      ">386, d[0.838,0.678], g[1.304] q[0.100]\n",
      ">387, d[0.570,0.871], g[1.168] q[0.097]\n",
      ">388, d[0.714,0.684], g[0.913] q[0.091]\n",
      ">389, d[0.397,0.522], g[1.184] q[0.094]\n",
      ">390, d[0.694,0.897], g[1.477] q[0.106]\n",
      ">391, d[0.590,0.500], g[1.177] q[0.115]\n",
      ">392, d[0.830,0.673], g[1.071] q[0.280]\n",
      ">393, d[0.719,0.844], g[1.207] q[0.165]\n",
      ">394, d[0.580,0.804], g[1.507] q[0.081]\n",
      ">395, d[0.629,0.574], g[1.510] q[0.117]\n",
      ">396, d[0.578,0.502], g[1.471] q[0.067]\n",
      ">397, d[0.556,0.571], g[1.254] q[0.072]\n",
      ">398, d[0.650,0.637], g[1.102] q[0.046]\n",
      ">399, d[0.628,0.517], g[1.128] q[0.059]\n",
      ">400, d[0.424,0.509], g[1.467] q[0.105]\n",
      ">401, d[0.759,0.608], g[1.097] q[0.089]\n",
      ">402, d[0.484,0.534], g[1.203] q[0.033]\n",
      ">403, d[0.730,0.645], g[0.901] q[0.062]\n",
      ">404, d[0.385,0.462], g[1.204] q[0.060]\n",
      ">405, d[0.585,0.745], g[1.244] q[0.070]\n",
      ">406, d[0.778,0.533], g[1.253] q[0.100]\n",
      ">407, d[0.642,0.643], g[1.144] q[0.074]\n",
      ">408, d[0.615,0.718], g[1.325] q[0.066]\n",
      ">409, d[0.376,0.518], g[1.422] q[0.072]\n",
      ">410, d[0.785,0.426], g[1.303] q[0.034]\n",
      ">411, d[0.674,0.634], g[1.307] q[0.056]\n",
      ">412, d[0.398,0.585], g[1.283] q[0.050]\n",
      ">413, d[0.684,0.676], g[1.253] q[0.030]\n",
      ">414, d[0.496,0.645], g[1.424] q[0.051]\n",
      ">415, d[0.717,0.569], g[1.310] q[0.071]\n",
      ">416, d[0.370,0.499], g[1.225] q[0.109]\n",
      ">417, d[0.461,0.523], g[1.262] q[0.066]\n",
      ">418, d[0.190,0.630], g[1.717] q[0.041]\n",
      ">419, d[0.326,0.506], g[1.825] q[0.131]\n",
      ">420, d[0.874,0.577], g[1.300] q[0.332]\n",
      ">421, d[0.595,0.829], g[1.254] q[0.128]\n",
      ">422, d[1.184,1.050], g[1.277] q[0.081]\n",
      ">423, d[0.919,0.566], g[0.910] q[0.129]\n",
      ">424, d[0.654,0.696], g[1.025] q[0.104]\n",
      ">425, d[0.765,1.137], g[0.987] q[0.251]\n",
      ">426, d[0.463,0.396], g[1.707] q[0.016]\n",
      ">427, d[0.800,0.624], g[1.240] q[0.102]\n",
      ">428, d[0.788,0.764], g[1.369] q[0.049]\n",
      ">429, d[0.862,0.542], g[1.062] q[0.143]\n",
      ">430, d[0.589,0.666], g[1.025] q[0.103]\n",
      ">431, d[0.650,0.690], g[1.069] q[0.071]\n",
      ">432, d[0.342,0.548], g[1.152] q[0.074]\n",
      ">433, d[0.738,0.436], g[1.433] q[0.045]\n",
      ">434, d[0.576,0.607], g[1.201] q[0.028]\n",
      ">435, d[0.555,0.642], g[1.236] q[0.029]\n",
      ">436, d[0.609,0.626], g[1.287] q[0.075]\n",
      ">437, d[0.518,0.641], g[1.175] q[0.060]\n",
      ">438, d[0.543,0.515], g[1.251] q[0.028]\n",
      ">439, d[0.756,0.612], g[0.838] q[0.020]\n",
      ">440, d[0.562,0.707], g[1.022] q[0.076]\n",
      ">441, d[0.653,0.648], g[1.067] q[0.037]\n",
      ">442, d[0.646,0.691], g[1.075] q[0.054]\n",
      ">443, d[0.394,0.771], g[1.397] q[0.040]\n",
      ">444, d[0.586,0.523], g[1.361] q[0.071]\n",
      ">445, d[0.606,0.406], g[1.431] q[0.041]\n",
      ">446, d[0.510,0.432], g[1.486] q[0.132]\n",
      ">447, d[0.679,0.544], g[1.039] q[0.104]\n",
      ">448, d[0.385,0.599], g[1.354] q[0.028]\n",
      ">449, d[0.501,0.692], g[1.375] q[0.033]\n",
      ">450, d[0.556,1.106], g[1.675] q[0.046]\n",
      ">451, d[1.319,0.460], g[1.216] q[0.201]\n",
      ">452, d[0.525,0.794], g[1.338] q[0.056]\n",
      ">453, d[0.583,0.540], g[1.293] q[0.098]\n",
      ">454, d[0.714,0.497], g[1.044] q[0.082]\n",
      ">455, d[0.399,0.598], g[1.352] q[0.042]\n",
      ">456, d[0.701,0.838], g[1.317] q[0.080]\n",
      ">457, d[0.525,0.841], g[1.596] q[0.048]\n",
      ">458, d[0.673,0.443], g[1.569] q[0.036]\n",
      ">459, d[0.416,0.446], g[1.301] q[0.064]\n",
      ">460, d[0.487,0.516], g[1.394] q[0.092]\n",
      ">461, d[0.335,0.458], g[1.118] q[0.075]\n",
      ">462, d[0.962,0.469], g[1.243] q[0.064]\n",
      ">463, d[0.653,0.456], g[1.038] q[0.134]\n",
      ">464, d[0.680,0.946], g[1.013] q[0.165]\n",
      ">465, d[0.378,0.581], g[1.220] q[0.213]\n",
      ">466, d[0.650,0.507], g[1.002] q[0.172]\n",
      ">467, d[0.724,1.516], g[1.288] q[0.130]\n",
      ">468, d[0.541,0.820], g[1.368] q[0.171]\n",
      ">469, d[0.963,0.447], g[1.222] q[0.187]\n",
      ">470, d[0.464,0.719], g[1.287] q[0.081]\n",
      ">471, d[0.560,0.433], g[0.996] q[0.216]\n",
      ">472, d[0.652,0.690], g[0.827] q[0.147]\n",
      ">473, d[0.319,0.702], g[1.624] q[0.038]\n",
      ">474, d[0.360,0.516], g[1.454] q[0.141]\n",
      ">475, d[0.816,0.287], g[1.523] q[0.144]\n",
      ">476, d[0.589,0.996], g[1.155] q[0.174]\n",
      ">477, d[0.425,0.537], g[1.173] q[0.080]\n",
      ">478, d[1.174,0.443], g[1.138] q[0.093]\n",
      ">479, d[0.391,0.499], g[1.244] q[0.077]\n",
      ">480, d[0.775,0.666], g[1.113] q[0.036]\n",
      ">481, d[0.648,0.666], g[1.143] q[0.078]\n",
      ">482, d[0.490,0.738], g[1.313] q[0.017]\n",
      ">483, d[0.499,0.676], g[1.567] q[0.023]\n",
      ">484, d[0.382,0.483], g[1.227] q[0.144]\n",
      ">485, d[1.035,0.750], g[1.328] q[0.066]\n",
      ">486, d[0.395,0.562], g[1.823] q[0.095]\n",
      ">487, d[0.950,0.464], g[1.330] q[0.050]\n",
      ">488, d[0.718,0.707], g[1.049] q[0.093]\n",
      ">489, d[0.826,0.898], g[0.917] q[0.036]\n",
      ">490, d[0.460,0.655], g[1.377] q[0.155]\n",
      ">491, d[0.625,0.675], g[1.181] q[0.145]\n",
      ">492, d[0.543,0.722], g[1.224] q[0.267]\n",
      ">493, d[0.858,0.627], g[1.040] q[0.096]\n",
      ">494, d[0.540,0.686], g[1.196] q[0.037]\n",
      ">495, d[0.617,0.668], g[1.379] q[0.124]\n",
      ">496, d[0.352,0.363], g[1.649] q[0.143]\n",
      ">497, d[0.437,0.387], g[1.408] q[0.055]\n",
      ">498, d[1.101,0.629], g[0.884] q[0.086]\n",
      ">499, d[0.513,0.722], g[0.712] q[0.069]\n",
      ">500, d[0.546,0.774], g[0.485] q[0.015]\n",
      ">501, d[0.296,0.799], g[1.318] q[0.034]\n",
      ">502, d[1.041,0.494], g[1.113] q[0.023]\n",
      ">503, d[0.667,0.683], g[1.277] q[0.034]\n",
      ">504, d[0.568,0.530], g[1.118] q[0.191]\n",
      ">505, d[0.833,0.758], g[1.085] q[0.091]\n",
      ">506, d[0.344,0.411], g[1.310] q[0.040]\n",
      ">507, d[0.725,0.558], g[1.248] q[0.031]\n",
      ">508, d[0.305,0.516], g[1.264] q[0.064]\n",
      ">509, d[0.488,0.410], g[1.009] q[0.074]\n",
      ">510, d[0.277,0.591], g[1.299] q[0.028]\n",
      ">511, d[0.895,0.883], g[1.581] q[0.031]\n",
      ">512, d[0.515,0.402], g[1.533] q[0.034]\n",
      ">513, d[0.797,0.521], g[1.222] q[0.229]\n",
      ">514, d[0.291,0.480], g[1.320] q[0.051]\n",
      ">515, d[0.702,0.474], g[1.134] q[0.123]\n",
      ">516, d[0.458,0.525], g[1.349] q[0.093]\n",
      ">517, d[0.522,0.463], g[0.935] q[0.087]\n",
      ">518, d[0.788,0.721], g[1.201] q[0.216]\n",
      ">519, d[0.483,0.651], g[0.930] q[0.106]\n",
      ">520, d[0.132,0.431], g[1.205] q[0.044]\n",
      ">521, d[1.005,0.403], g[1.085] q[0.192]\n",
      ">522, d[0.477,0.731], g[1.071] q[0.174]\n",
      ">523, d[0.416,0.877], g[1.141] q[0.095]\n",
      ">524, d[0.676,0.864], g[1.270] q[0.165]\n",
      ">525, d[0.843,0.708], g[1.212] q[0.194]\n",
      ">526, d[0.970,0.970], g[1.072] q[0.441]\n",
      ">527, d[0.650,0.625], g[1.262] q[0.124]\n",
      ">528, d[0.764,0.666], g[1.106] q[0.300]\n",
      ">529, d[0.676,0.757], g[1.266] q[0.026]\n",
      ">530, d[0.499,0.620], g[1.361] q[0.212]\n",
      ">531, d[0.663,0.786], g[1.200] q[0.045]\n",
      ">532, d[0.747,0.611], g[1.282] q[0.026]\n",
      ">533, d[0.751,0.732], g[0.891] q[0.077]\n",
      ">534, d[0.526,0.728], g[1.280] q[0.042]\n",
      ">535, d[0.703,0.662], g[1.171] q[0.046]\n",
      ">536, d[0.739,0.679], g[1.071] q[0.009]\n",
      ">537, d[0.691,0.755], g[1.051] q[0.013]\n",
      ">538, d[0.653,0.387], g[0.879] q[0.022]\n",
      ">539, d[0.705,0.819], g[0.796] q[0.019]\n",
      ">540, d[0.799,0.653], g[0.937] q[0.026]\n",
      ">541, d[0.575,0.680], g[0.917] q[0.028]\n",
      ">542, d[0.186,0.478], g[1.329] q[0.082]\n",
      ">543, d[1.030,0.600], g[1.070] q[0.017]\n",
      ">544, d[0.655,0.653], g[0.865] q[0.042]\n",
      ">545, d[0.592,0.712], g[1.044] q[0.029]\n",
      ">546, d[0.526,0.707], g[1.340] q[0.017]\n",
      ">547, d[0.731,0.701], g[1.021] q[0.155]\n",
      ">548, d[0.669,0.677], g[1.066] q[0.159]\n",
      ">549, d[0.244,0.482], g[1.476] q[0.024]\n",
      ">550, d[1.160,0.589], g[1.118] q[0.039]\n",
      ">551, d[0.693,0.582], g[0.758] q[0.022]\n",
      ">552, d[0.569,0.585], g[0.655] q[0.186]\n",
      ">553, d[0.335,0.645], g[1.381] q[0.031]\n",
      ">554, d[0.582,0.723], g[1.620] q[0.049]\n",
      ">555, d[0.854,0.591], g[1.048] q[0.021]\n",
      ">556, d[0.216,0.488], g[1.445] q[0.029]\n",
      ">557, d[0.491,0.620], g[1.340] q[0.035]\n",
      ">558, d[0.652,0.529], g[1.273] q[0.111]\n",
      ">559, d[0.355,0.821], g[1.649] q[0.139]\n",
      ">560, d[1.274,0.450], g[1.213] q[0.026]\n",
      ">561, d[0.787,0.682], g[1.052] q[0.066]\n",
      ">562, d[0.398,0.518], g[1.331] q[0.068]\n",
      ">563, d[0.606,0.698], g[1.040] q[0.072]\n",
      ">564, d[0.318,0.404], g[1.394] q[0.027]\n",
      ">565, d[0.978,0.428], g[1.216] q[0.023]\n",
      ">566, d[0.853,0.813], g[0.919] q[0.048]\n",
      ">567, d[0.488,0.621], g[1.112] q[0.033]\n",
      ">568, d[0.827,0.757], g[0.990] q[0.046]\n",
      ">569, d[0.517,0.638], g[1.302] q[0.024]\n",
      ">570, d[0.740,0.661], g[1.091] q[0.049]\n",
      ">571, d[0.376,0.475], g[1.175] q[0.056]\n",
      ">572, d[0.705,0.443], g[1.053] q[0.035]\n",
      ">573, d[0.624,0.770], g[1.131] q[0.027]\n",
      ">574, d[0.573,0.670], g[1.375] q[0.049]\n",
      ">575, d[0.714,0.539], g[1.187] q[0.025]\n",
      ">576, d[0.504,0.541], g[1.269] q[0.081]\n",
      ">577, d[0.791,0.768], g[1.057] q[0.019]\n",
      ">578, d[0.268,0.557], g[1.365] q[0.035]\n",
      ">579, d[0.987,0.507], g[0.998] q[0.090]\n",
      ">580, d[0.440,0.560], g[0.798] q[0.066]\n",
      ">581, d[0.320,1.226], g[1.550] q[0.160]\n",
      ">582, d[0.414,0.287], g[1.324] q[0.094]\n",
      ">583, d[0.962,0.735], g[1.377] q[0.072]\n",
      ">584, d[0.684,0.759], g[1.343] q[0.024]\n",
      ">585, d[0.531,0.518], g[1.434] q[0.028]\n",
      ">586, d[0.596,0.506], g[1.033] q[0.097]\n",
      ">587, d[0.263,0.492], g[1.595] q[0.014]\n",
      ">588, d[0.240,0.385], g[0.925] q[0.063]\n",
      ">589, d[0.803,0.381], g[1.136] q[0.016]\n",
      ">590, d[0.759,1.648], g[1.439] q[0.065]\n",
      ">591, d[0.482,0.357], g[1.028] q[0.098]\n",
      ">592, d[0.835,0.588], g[1.147] q[0.030]\n",
      ">593, d[0.414,0.672], g[1.036] q[0.133]\n",
      ">594, d[1.203,0.637], g[1.220] q[0.089]\n",
      ">595, d[0.437,0.788], g[0.511] q[0.191]\n",
      ">596, d[0.653,0.708], g[1.276] q[0.130]\n",
      ">597, d[0.675,0.887], g[1.570] q[0.191]\n",
      ">598, d[1.059,0.763], g[1.014] q[0.344]\n",
      ">599, d[0.745,0.656], g[0.803] q[0.069]\n",
      ">600, d[0.491,0.802], g[0.921] q[0.402]\n",
      ">601, d[1.096,0.523], g[1.049] q[0.189]\n",
      ">602, d[0.577,0.510], g[1.136] q[0.036]\n",
      ">603, d[0.624,0.808], g[1.037] q[0.181]\n",
      ">604, d[0.503,0.665], g[1.438] q[0.162]\n",
      ">605, d[0.777,0.537], g[1.308] q[0.155]\n",
      ">606, d[0.595,0.737], g[1.010] q[0.059]\n",
      ">607, d[0.635,0.681], g[0.958] q[0.062]\n",
      ">608, d[0.570,0.691], g[1.130] q[0.032]\n",
      ">609, d[0.389,0.790], g[1.424] q[0.134]\n",
      ">610, d[0.817,0.460], g[1.408] q[0.058]\n",
      ">611, d[0.656,0.565], g[1.138] q[0.029]\n",
      ">612, d[0.781,0.661], g[0.984] q[0.031]\n",
      ">613, d[0.630,0.725], g[0.939] q[0.304]\n",
      ">614, d[0.495,0.819], g[1.184] q[0.021]\n",
      ">615, d[0.688,0.670], g[1.091] q[0.157]\n",
      ">616, d[0.624,0.602], g[1.142] q[0.042]\n",
      ">617, d[0.636,0.591], g[1.008] q[0.030]\n",
      ">618, d[0.549,0.670], g[1.119] q[0.055]\n",
      ">619, d[0.567,0.724], g[0.916] q[0.147]\n",
      ">620, d[0.642,0.690], g[0.945] q[0.076]\n",
      ">621, d[0.622,0.725], g[1.029] q[0.056]\n",
      ">622, d[0.552,0.653], g[1.210] q[0.047]\n",
      ">623, d[0.532,0.470], g[1.242] q[0.102]\n",
      ">624, d[0.911,0.576], g[1.230] q[0.091]\n",
      ">625, d[0.519,0.683], g[1.035] q[0.016]\n",
      ">626, d[0.570,0.661], g[1.027] q[0.020]\n",
      ">627, d[0.587,0.582], g[1.142] q[0.008]\n",
      ">628, d[0.761,0.748], g[0.966] q[0.010]\n",
      ">629, d[0.668,0.604], g[0.947] q[0.074]\n",
      ">630, d[0.633,0.692], g[1.198] q[0.077]\n",
      ">631, d[0.550,0.844], g[1.260] q[0.051]\n",
      ">632, d[0.825,0.509], g[1.237] q[0.023]\n",
      ">633, d[0.779,0.583], g[0.926] q[0.021]\n",
      ">634, d[0.327,0.650], g[1.228] q[0.056]\n",
      ">635, d[0.931,0.595], g[1.040] q[0.028]\n",
      ">636, d[0.211,0.480], g[1.372] q[0.030]\n",
      ">637, d[0.741,0.622], g[1.264] q[0.108]\n",
      ">638, d[0.685,0.723], g[1.041] q[0.074]\n",
      ">639, d[0.237,0.550], g[1.664] q[0.016]\n",
      ">640, d[1.249,0.519], g[1.189] q[0.113]\n",
      ">641, d[0.594,0.792], g[1.010] q[0.314]\n",
      ">642, d[0.472,0.634], g[1.329] q[0.014]\n",
      ">643, d[0.880,0.610], g[1.104] q[0.047]\n",
      ">644, d[0.698,0.759], g[0.979] q[0.124]\n",
      ">645, d[0.736,0.621], g[1.084] q[0.051]\n",
      ">646, d[0.350,0.601], g[1.454] q[0.016]\n",
      ">647, d[0.762,0.396], g[1.074] q[0.087]\n",
      ">648, d[0.552,0.601], g[1.043] q[0.036]\n",
      ">649, d[0.526,0.724], g[1.177] q[0.058]\n",
      ">650, d[0.542,0.630], g[1.218] q[0.034]\n",
      ">651, d[0.511,0.529], g[1.299] q[0.028]\n",
      ">652, d[0.379,0.569], g[1.204] q[0.059]\n",
      ">653, d[0.491,0.422], g[1.219] q[0.044]\n",
      ">654, d[0.599,0.811], g[1.499] q[0.031]\n",
      ">655, d[0.784,0.500], g[1.328] q[0.145]\n",
      ">656, d[0.464,0.493], g[1.550] q[0.034]\n",
      ">657, d[0.904,0.489], g[1.061] q[0.020]\n",
      ">658, d[0.398,0.874], g[1.118] q[0.028]\n",
      ">659, d[0.772,0.568], g[1.258] q[0.065]\n",
      ">660, d[0.619,0.733], g[1.188] q[0.057]\n",
      ">661, d[0.793,0.678], g[1.297] q[0.122]\n",
      ">662, d[0.694,0.735], g[1.160] q[0.016]\n",
      ">663, d[0.554,0.627], g[0.913] q[0.084]\n",
      ">664, d[0.662,0.536], g[1.182] q[0.160]\n",
      ">665, d[0.483,0.556], g[1.176] q[0.052]\n",
      ">666, d[0.491,0.513], g[1.194] q[0.014]\n",
      ">667, d[0.571,0.575], g[1.470] q[0.107]\n",
      ">668, d[0.829,0.511], g[0.882] q[0.052]\n",
      ">669, d[0.815,0.661], g[1.281] q[0.131]\n",
      ">670, d[0.386,0.646], g[1.247] q[0.094]\n",
      ">671, d[0.660,0.567], g[1.271] q[0.027]\n",
      ">672, d[0.778,0.536], g[0.980] q[0.083]\n",
      ">673, d[0.427,0.775], g[0.879] q[0.016]\n",
      ">674, d[0.479,0.590], g[1.148] q[0.014]\n",
      ">675, d[0.614,0.641], g[0.969] q[0.028]\n",
      ">676, d[0.595,0.585], g[1.069] q[0.018]\n",
      ">677, d[0.370,0.496], g[1.146] q[0.008]\n",
      ">678, d[0.831,0.557], g[1.053] q[0.087]\n",
      ">679, d[0.648,0.698], g[1.030] q[0.088]\n",
      ">680, d[0.464,0.640], g[1.027] q[0.066]\n",
      ">681, d[0.620,0.651], g[1.051] q[0.044]\n",
      ">682, d[0.735,0.842], g[1.070] q[0.053]\n",
      ">683, d[0.440,0.520], g[1.384] q[0.014]\n",
      ">684, d[0.334,0.413], g[1.379] q[0.011]\n",
      ">685, d[0.660,0.458], g[1.253] q[0.026]\n",
      ">686, d[0.562,0.583], g[1.141] q[0.063]\n",
      ">687, d[0.246,0.485], g[1.337] q[0.033]\n",
      ">688, d[0.351,0.553], g[1.517] q[0.086]\n",
      ">689, d[0.429,0.373], g[1.623] q[0.038]\n",
      ">690, d[0.827,0.797], g[1.425] q[0.072]\n",
      ">691, d[0.298,0.408], g[1.555] q[0.091]\n",
      ">692, d[0.858,0.373], g[0.718] q[0.136]\n",
      ">693, d[0.440,0.525], g[1.205] q[0.082]\n",
      ">694, d[0.263,0.411], g[1.537] q[0.073]\n",
      ">695, d[0.365,0.366], g[1.386] q[0.024]\n",
      ">696, d[0.426,0.864], g[1.819] q[0.055]\n",
      ">697, d[0.968,0.635], g[1.508] q[0.191]\n",
      ">698, d[1.052,0.504], g[1.036] q[0.067]\n",
      ">699, d[0.471,0.933], g[1.081] q[0.071]\n",
      ">700, d[0.512,0.437], g[1.022] q[0.204]\n",
      ">701, d[0.991,0.388], g[0.758] q[0.139]\n",
      ">702, d[0.325,0.885], g[1.091] q[0.032]\n",
      ">703, d[0.751,0.742], g[0.830] q[0.097]\n",
      ">704, d[0.611,0.644], g[1.158] q[0.072]\n",
      ">705, d[0.421,0.436], g[1.403] q[0.046]\n",
      ">706, d[0.420,1.080], g[1.707] q[0.025]\n",
      ">707, d[1.257,0.635], g[1.433] q[0.100]\n",
      ">708, d[0.660,0.537], g[1.487] q[0.064]\n",
      ">709, d[0.740,0.499], g[0.845] q[0.081]\n",
      ">710, d[0.651,0.716], g[1.170] q[0.077]\n",
      ">711, d[0.629,0.733], g[1.073] q[0.053]\n",
      ">712, d[0.821,0.769], g[0.508] q[0.029]\n",
      ">713, d[0.643,0.761], g[1.348] q[0.084]\n",
      ">714, d[0.629,0.648], g[1.210] q[0.145]\n",
      ">715, d[0.748,0.539], g[0.606] q[0.024]\n",
      ">716, d[0.487,0.951], g[1.135] q[0.044]\n",
      ">717, d[0.661,0.813], g[1.034] q[0.034]\n",
      ">718, d[0.499,0.529], g[1.232] q[0.025]\n",
      ">719, d[0.756,0.544], g[0.743] q[0.097]\n",
      ">720, d[0.757,0.574], g[1.016] q[0.060]\n",
      ">721, d[0.657,0.642], g[1.190] q[0.083]\n",
      ">722, d[0.646,0.659], g[1.291] q[0.040]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-2ba45f985923>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mgan\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgen_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdiscr_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfogan_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-10-5f55f1098272>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, gen_model, discr_model, infogan_model, dataset, n_epochs)\u001b[0m\n\u001b[1;32m    204\u001b[0m             \u001b[0my_gan\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m             \u001b[0;31m# update the g via the d and q error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 206\u001b[0;31m             \u001b[0mgan_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minfogan_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0my_gan\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcat_codes\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    207\u001b[0m             \u001b[0;31m# summarize loss on this batch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'>%d, d[%.3f,%.3f], g[%.3f] q[%.3f]'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md_loss1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md_loss2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgan_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgan_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1098\u001b[0m                 _r=1):\n\u001b[1;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1101\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    853\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    854\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 855\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    856\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    857\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2942\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2943\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2945\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1917\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1918\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1919\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1921\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    558\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    561\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "gan.train(gen_model, discr_model, infogan_model, ds, n_epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
