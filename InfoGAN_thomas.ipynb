{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import zeros\n",
    "from numpy import ones\n",
    "from numpy import expand_dims\n",
    "from numpy import hstack\n",
    "from numpy.random import randn\n",
    "from numpy.random import randint\n",
    "from keras.datasets.mnist import load_data\n",
    "from keras.optimizers import Adam\n",
    "from keras.initializers import RandomNormal\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Model\n",
    "from keras import layers\n",
    "import tensorflow_datasets as tfds\n",
    "import tensorflow as tf\n",
    "class InfoGAN:\n",
    "    def __init__(self):\n",
    "        \n",
    "        #Define the discriminator model:\n",
    "        # number of values for the categorical control code\n",
    "        self.n_cat = 10\n",
    "        # size of the latent space\n",
    "        self.latent_dim = 62\n",
    "        #Define size of generator input\n",
    "        self.gen_input_size = self.latent_dim + self.n_cat\n",
    "        self.batch_size=128\n",
    "        \n",
    "    def normalize_img(self,image,label):\n",
    "        label=1\n",
    "        return tf.cast(image, tf.float32) / 255.,label\n",
    "         \n",
    "    def load_MNIST(self):\n",
    "        ds, ds_info = tfds.load('mnist', split='train', with_info=True,as_supervised=True)\n",
    "        shape=ds_info.features['image'].shape\n",
    "        ds = ds.map(self.normalize_img, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "        ds = ds.shuffle(ds_info.splits['train'].num_examples)\n",
    "        ds=ds.batch(self.batch_size)\n",
    "        return ds,ds_info, shape\n",
    "    \n",
    "    def load_SVHN(self):\n",
    "        ds, ds_info = tfds.load('svhn_cropped', split='train', with_info=True,as_supervised=True)\n",
    "        shape=ds_info.features['image'].shape\n",
    "        ds = ds.map(self.normalize_img, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "        ds = ds.shuffle(ds_info.splits['train'].num_examples)\n",
    "        ds=ds.batch(self.batch_size)\n",
    "        return ds,ds_info, shape\n",
    "    \n",
    "    def load_CELEBA(self):\n",
    "        #To Do, access via tensorflow datasets seems to be broken due to the ds being hosted on Drive\n",
    "        pass\n",
    "\n",
    "    def show_examples(self,ds, ds_info):\n",
    "        fig = tfds.show_examples(ds, ds_info)\n",
    "\n",
    "    #Define the generator model:\n",
    "    def get_generator(self,shape):\n",
    "        input_latent = layers.Input(shape=(self.gen_input_size))\n",
    "        \n",
    "        #The various datasets have various sizes and #channels so the dimension of the generator needs to be variable\n",
    "        res=int(shape[0]/4)\n",
    "        depth=int(shape[-1])\n",
    "        \n",
    "        n_nodes = 512 * res * res\n",
    "\n",
    "        g = layers.Dense(n_nodes)(input_latent)\n",
    "        g = layers.ReLU()(g)\n",
    "        g = layers.BatchNormalization()(g)\n",
    "        g = layers.Reshape((res, res, 512))(g)\n",
    "\n",
    "        g = layers.Conv2D(128, 4, padding='same',activation='relu')(g)\n",
    "        g = layers.ReLU()(g)\n",
    "        g = layers.BatchNormalization()(g)\n",
    "\n",
    "        g = layers.Conv2DTranspose(64, 4, strides=(2,2), padding='same')(g)\n",
    "        g = layers.ReLU()(g)\n",
    "        g = layers.BatchNormalization()(g)\n",
    "        g = layers.Conv2DTranspose(depth, 4, strides=(2,2), padding='same')(g)\n",
    "        # tanh output\n",
    "        output_layer = layers.Activation('sigmoid')(g)\n",
    "        # define the generator model\n",
    "        gen_model = Model(input_latent, output_layer)\n",
    "        return gen_model\n",
    "    \n",
    "    \n",
    "    def get_discr_q(self,input_shape):\n",
    "        input_image=layers.Input(shape=input_shape)\n",
    "\n",
    "        l=layers.Conv2D(64, 4, strides=(2,2),padding='same')(input_image)\n",
    "        l=layers.ReLU()(l)\n",
    "\n",
    "        l=layers.Conv2D(128, 4, strides=(2,2), padding='same')(l)\n",
    "        l=layers.ReLU()(l)\n",
    "        l=layers.BatchNormalization()(l)\n",
    "\n",
    "        l=layers.Conv2D(256, 4, strides=(2,2), padding='same')(l)\n",
    "        l=layers.ReLU()(l)\n",
    "        l=layers.BatchNormalization()(l)\n",
    "\n",
    "        l=layers.Flatten()(l)\n",
    "        #Classification head of the discriminator\n",
    "        out=layers.Dense(1,activation='sigmoid')(l)\n",
    "        discr_model = Model(input_image, out)\n",
    "        discr_model.compile(loss='binary_crossentropy', optimizer=Adam(lr=0.001, beta_1=0.9))\n",
    "        # create q model layers\n",
    "        q = layers.Dense(128)(l)\n",
    "        q = layers.BatchNormalization()(q)\n",
    "        q = layers.LeakyReLU(alpha=0.1)(q)\n",
    "        # q model output\n",
    "        out_codes = layers.Dense(self.n_cat, activation='softmax')(q)\n",
    "        # define q model\n",
    "        q_model = Model(input_image, out_codes)\n",
    "        return discr_model, q_model\n",
    "    \n",
    "    def infogan(self,gen_model, discr_model, q_model):\n",
    "        # make weights in the discriminator (some shared with the q model) as not trainable\n",
    "        for layer in discr_model.layers:\n",
    "            if not isinstance(layer, layers.BatchNormalization):\n",
    "                layer.trainable = False\n",
    "        # connect g outputs to d inputs\n",
    "        discr_output = discr_model(gen_model.output)\n",
    "        # connect g outputs to q inputs\n",
    "        q_output = q_model(gen_model.output)\n",
    "        # define composite model\n",
    "        infogan_model = Model(gen_model.input, [discr_output, q_output])\n",
    "        # compile model\n",
    "        opt = Adam(lr=0.001, beta_1=0.9)\n",
    "        infogan_model.compile(loss=['binary_crossentropy', 'categorical_crossentropy'], optimizer=opt)\n",
    "        return infogan_model\n",
    "    \n",
    "\n",
    "    # generate points in latent space as input for the generator\n",
    "    def generate_noise(self, n_samples):\n",
    "        # generate points in the latent space\n",
    "        z_latent=randn(n_samples,self.latent_dim)\n",
    "        # generate categorical one-hot codes\n",
    "        cat_codes=np.eye(self.n_cat)[np.random.choice(self.n_cat, n_samples)]\n",
    "        # concatenate latent points and control codes\n",
    "        z_input = hstack((z_latent, cat_codes))\n",
    "        return [z_input, cat_codes]\n",
    "    \n",
    "    # use the generator to generate n fake examples, with class labels\n",
    "    def generate_noise_samples(generator, latent_dim, n_cat, n_samples):\n",
    "        # generate points in latent space and control codes\n",
    "        z_input, _ = generate_latent_points(latent_dim, n_cat, n_samples)\n",
    "        # predict outputs\n",
    "        images = generator.predict(z_input)\n",
    "        # create class labels\n",
    "        y = zeros((n_samples, 1))\n",
    "        return images, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "gan=InfoGAN()\n",
    "ds,ds_info, shape=gan.load_SVHN()\n",
    "gen_test=gan.get_generator(shape)\n",
    "discr_test,q_test=gan.get_discr_q(shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "info_test=gan.infogan(gen_test,discr_test,q_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_train = ds.batch(128)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "test=list(ds.as_numpy_iterator())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 6s 6s/step - loss: 1.6646e-07\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7ffc72a3fed0>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "discr_test.fit(ds_train,steps_per_epoch=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
