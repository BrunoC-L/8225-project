{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import zeros\n",
    "from numpy import ones\n",
    "from numpy import expand_dims\n",
    "from numpy import hstack\n",
    "from numpy.random import randn\n",
    "from numpy.random import randint\n",
    "from keras.datasets.mnist import load_data\n",
    "from keras.optimizers import Adam\n",
    "from keras.initializers import RandomNormal\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Model\n",
    "from keras import layers\n",
    "import tensorflow_datasets as tfds\n",
    "import tensorflow as tf\n",
    "from matplotlib import pyplot\n",
    "\n",
    "class InfoGAN:\n",
    "    def __init__(self):\n",
    "        \n",
    "        # number of values for the categorical control code\n",
    "        self.n_cat = 10\n",
    "        # size of the latent space\n",
    "        self.latent_dim = 62\n",
    "        #Define size of generator input\n",
    "        self.gen_input_size = self.latent_dim + self.n_cat\n",
    "        self.batch_size=128\n",
    "        self.kernel_init = RandomNormal(stddev=0.02)\n",
    "\n",
    "    def normalize_img(self,image,label):\n",
    "        label=1\n",
    "        return tf.cast(image, tf.float32) / 255.,label\n",
    "         \n",
    "    def load_MNIST(self):\n",
    "        ds, ds_info = tfds.load('mnist', split='train', with_info=True,as_supervised=True)\n",
    "        shape=ds_info.features['image'].shape\n",
    "        ds = ds.map(self.normalize_img, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "        ds = ds.shuffle(ds_info.splits['train'].num_examples)\n",
    "        ds=ds.batch(self.batch_size)\n",
    "        return ds,ds_info, shape\n",
    "    \n",
    "    def load_SVHN(self):\n",
    "        ds, ds_info = tfds.load('svhn_cropped', split='train', with_info=True,as_supervised=True)\n",
    "        shape=ds_info.features['image'].shape\n",
    "        ds = ds.map(self.normalize_img, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "        ds = ds.shuffle(ds_info.splits['train'].num_examples)\n",
    "        ds=ds.batch(self.batch_size)\n",
    "        return ds,ds_info, shape\n",
    "    \n",
    "    def load_CELEBA(self):\n",
    "        #To Do, access via tensorflow datasets seems to be broken due to the ds being hosted on Drive\n",
    "        pass\n",
    "\n",
    "    def show_real_examples(self,ds, ds_info):\n",
    "        fig = tfds.show_examples(ds, ds_info)\n",
    "\n",
    "    #Define the generator model:\n",
    "    def get_generator(self,shape):\n",
    "        input_latent = layers.Input(shape=(self.gen_input_size))\n",
    "        \n",
    "        #The various datasets have various sizes and #channels so the dimension of the generator needs to be variable\n",
    "        res=int(shape[0]/4)\n",
    "        depth=int(shape[-1])\n",
    "        \n",
    "        n_nodes = 512 * res * res\n",
    "\n",
    "        g = layers.Dense(n_nodes)(input_latent)\n",
    "        g = layers.ReLU()(g)\n",
    "        g = layers.BatchNormalization()(g)\n",
    "        g = layers.Reshape((res, res, 512))(g)\n",
    "\n",
    "        g = layers.Conv2D(128, 4, padding='same',activation='relu',kernel_initializer=self.kernel_init)(g)\n",
    "        g = layers.ReLU()(g)\n",
    "        g = layers.BatchNormalization()(g)\n",
    "\n",
    "        g = layers.Conv2DTranspose(64, 4, strides=(2,2), padding='same',kernel_initializer=self.kernel_init)(g)\n",
    "        g = layers.ReLU()(g)\n",
    "        g = layers.BatchNormalization()(g)\n",
    "        g = layers.Conv2DTranspose(depth, 4, strides=(2,2), padding='same',kernel_initializer=self.kernel_init)(g)\n",
    "        # Sigmoid output\n",
    "        output_layer = layers.Activation('sigmoid')(g)\n",
    "        # define the generator model\n",
    "        gen_model = Model(input_latent, output_layer)\n",
    "        return gen_model\n",
    "    \n",
    "    \n",
    "    def get_discr_q(self,input_shape):\n",
    "        input_image=layers.Input(shape=input_shape)\n",
    "\n",
    "        l=layers.Conv2D(64, 4, strides=(2,2),padding='same',kernel_initializer=self.kernel_init)(input_image)\n",
    "        l=layers.ReLU()(l)\n",
    "\n",
    "        l=layers.Conv2D(128, 4, strides=(2,2), padding='same',kernel_initializer=self.kernel_init)(l)\n",
    "        l=layers.ReLU()(l)\n",
    "        l=layers.BatchNormalization()(l)\n",
    "\n",
    "        l=layers.Conv2D(256, 4, strides=(2,2), padding='same',kernel_initializer=self.kernel_init)(l)\n",
    "        l=layers.ReLU()(l)\n",
    "        l=layers.BatchNormalization()(l)\n",
    "\n",
    "        l=layers.Flatten()(l)\n",
    "        #Classification head of the discriminator\n",
    "        out=layers.Dense(1,activation='sigmoid')(l)\n",
    "        discr_model = Model(input_image, out)\n",
    "        discr_model.compile(loss='binary_crossentropy', optimizer=Adam(lr=0.0002, beta_1=0.5))\n",
    "        # create q model layers\n",
    "        q = layers.Dense(128)(l)\n",
    "        q = layers.BatchNormalization()(q)\n",
    "        q = layers.LeakyReLU(alpha=0.1)(q)\n",
    "        # q model output\n",
    "        out_codes = layers.Dense(self.n_cat, activation='softmax')(q)\n",
    "        # define q model\n",
    "        q_model = Model(input_image, out_codes)\n",
    "        return discr_model, q_model\n",
    "    \n",
    "    def infogan(self,gen_model, discr_model, q_model):\n",
    "        # make weights in the discriminator (some shared with the q model) as not trainable\n",
    "        for layer in discr_model.layers:\n",
    "            if not isinstance(layer, layers.BatchNormalization):\n",
    "                layer.trainable = False\n",
    "        # connect g outputs to d inputs\n",
    "        discr_output = discr_model(gen_model.output)\n",
    "        # connect g outputs to q inputs\n",
    "        q_output = q_model(gen_model.output)\n",
    "        # define composite model\n",
    "        infogan_model = Model(gen_model.input, [discr_output, q_output])\n",
    "        # compile model\n",
    "        opt = Adam(lr=0.0002, beta_1=0.5)\n",
    "        infogan_model.compile(loss=['binary_crossentropy', 'categorical_crossentropy'], optimizer=opt)\n",
    "        return infogan_model\n",
    "    \n",
    "\n",
    "    # generate points in latent space as input for the generator\n",
    "    def generate_noise(self, n_samples):\n",
    "        # generate points in the latent space\n",
    "        z_latent=randn(n_samples,self.latent_dim)\n",
    "        # generate categorical one-hot codes\n",
    "        cat_codes=np.eye(self.n_cat)[np.random.choice(self.n_cat, n_samples)]\n",
    "        # concatenate latent points and control codes\n",
    "        z_input = hstack((z_latent, cat_codes))\n",
    "        return [z_input, cat_codes]\n",
    "    \n",
    "    # use the generator to generate n fake examples, with class labels\n",
    "    def generate_fake_samples(self,generator, n_samples):\n",
    "        # generate points in latent space and control codes\n",
    "        z_input, _ = self.generate_noise(n_samples)\n",
    "        # predict outputs\n",
    "        images = generator.predict(z_input)\n",
    "        # create class labels\n",
    "        y = zeros((n_samples, 1))\n",
    "        return images, y\n",
    "    \n",
    "    def summarize_performance(self,step, gen_model, gan_model, n_samples=100):\n",
    "        # prepare fake examples\n",
    "        X, _ = self.generate_fake_samples(gen_model, n_samples)\n",
    "\n",
    "        # plot images\n",
    "        for i in range(n_samples):\n",
    "            # define subplot\n",
    "            pyplot.subplot(10, 10, 1 + i)\n",
    "            # turn off axis\n",
    "            pyplot.axis('off')\n",
    "            # plot raw pixel data\n",
    "            #pyplot.imshow(X[i, :, :, 0], cmap='gray_r')\n",
    "            pyplot.imshow(X[i, :, :, :])\n",
    "        # save plot to file\n",
    "        filename1 = 'generated_plot_%04d.png' % (step+1)\n",
    "        pyplot.savefig(filename1)\n",
    "        pyplot.close()\n",
    "        # save the generator model\n",
    "        filename2 = 'model_%04d.h5' % (step+1)\n",
    "        gen_model.save(filename2)\n",
    "        # save the gan model\n",
    "        filename3 = 'gan_model_%04d.h5' % (step+1)\n",
    "        gan_model.save(filename3)\n",
    "        print('>Saved: %s, %s, and %s' % (filename1, filename2, filename3))\n",
    "        \n",
    "    # train the generator and discriminator\n",
    "    def train(self,gen_model, discr_model, infogan_model, dataset, n_epochs=100):\n",
    "        # calculate the number of batches per training epoch\n",
    "        bat_per_epo = len(ds)\n",
    "        # calculate the number of training iterations\n",
    "        n_steps = bat_per_epo * n_epochs\n",
    "        # manually enumerate epochs\n",
    "        for i in range(n_steps):\n",
    "            # update discriminator and q model weights\n",
    "            d_loss1 = discr_model.fit(ds,steps_per_epoch=1,verbose=0)\n",
    "            # generate 'fake' examples\n",
    "            X_fake, y_fake = self.generate_fake_samples(gen_model, self.batch_size)\n",
    "            # update discriminator model weights\n",
    "            d_loss2 = discr_model.fit(X_fake, y_fake,verbose=0,batch_size=self.batch_size)\n",
    "            # prepare points in latent space as input for the generator\n",
    "            z_input, cat_codes = self.generate_noise(self.batch_size)\n",
    "            # create inverted labels for the fake samples\n",
    "            y_gan = ones((self.batch_size, 1))\n",
    "            # update the g via the d and q error\n",
    "            gan_loss = infogan_model.fit(z_input, [y_gan, cat_codes],verbose=0,batch_size=self.batch_size)\n",
    "            # summarize loss on this batch\n",
    "            print('>%d, d[%.3f,%.3f], g[%.3f] q[%.3f]' % (i+1, d_loss1.history['loss'][0], d_loss2.history['loss'][0], list(gan_loss.history.items())[1][1][0],list(gan_loss.history.items())[2][1][0]))\n",
    "            # evaluate the model performance every 'epoch'\n",
    "            if (i+1) % (bat_per_epo * 10) == 0:\n",
    "                self.summarize_performance(i, gen_model, infogan_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "gan=InfoGAN()\n",
    "ds,ds_info, shape=gan.load_MNIST()\n",
    "gen_model=gan.get_generator(shape)\n",
    "discr_model,q_model=gan.get_discr_q(shape)\n",
    "infogan_model=gan.infogan(gen_model, discr_model, q_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">1, d[0.445,1.181], g[4.634] q[2.596]\n",
      ">2, d[0.012,0.000], g[7.527] q[2.573]\n",
      ">3, d[0.006,0.000], g[7.940] q[2.366]\n",
      ">4, d[0.015,0.000], g[7.612] q[2.461]\n",
      ">5, d[0.004,0.000], g[7.181] q[2.128]\n",
      ">6, d[0.007,0.000], g[6.594] q[2.159]\n",
      ">7, d[0.002,0.000], g[6.057] q[2.012]\n",
      ">8, d[0.002,0.000], g[5.494] q[2.062]\n",
      ">9, d[0.008,0.000], g[4.788] q[1.844]\n",
      ">10, d[0.002,0.000], g[4.184] q[1.917]\n",
      ">11, d[0.002,0.000], g[3.659] q[1.697]\n",
      ">12, d[0.003,0.000], g[2.957] q[1.609]\n",
      ">13, d[0.002,0.000], g[2.346] q[1.571]\n",
      ">14, d[0.002,0.000], g[1.830] q[1.586]\n",
      ">15, d[0.002,0.000], g[1.347] q[1.374]\n",
      ">16, d[0.002,0.000], g[0.905] q[1.318]\n",
      ">17, d[0.002,0.000], g[0.702] q[1.178]\n",
      ">18, d[0.001,0.000], g[0.529] q[1.182]\n",
      ">19, d[0.001,0.000], g[0.423] q[1.068]\n",
      ">20, d[0.001,0.000], g[0.294] q[1.044]\n",
      ">21, d[0.001,0.000], g[0.242] q[0.936]\n",
      ">22, d[0.001,0.000], g[0.194] q[0.878]\n",
      ">23, d[0.001,0.000], g[0.163] q[0.820]\n",
      ">24, d[0.001,0.000], g[0.132] q[0.707]\n",
      ">25, d[0.002,0.000], g[0.119] q[0.646]\n",
      ">26, d[0.001,0.000], g[0.098] q[0.531]\n",
      ">27, d[0.001,0.000], g[0.104] q[0.494]\n",
      ">28, d[0.001,0.000], g[0.089] q[0.491]\n",
      ">29, d[0.001,0.000], g[0.081] q[0.488]\n",
      ">30, d[0.001,0.000], g[0.076] q[0.414]\n",
      ">31, d[0.001,0.000], g[0.072] q[0.349]\n",
      ">32, d[0.000,0.000], g[0.072] q[0.370]\n",
      ">33, d[0.001,0.000], g[0.067] q[0.285]\n",
      ">34, d[0.000,0.000], g[0.057] q[0.251]\n",
      ">35, d[0.001,0.000], g[0.054] q[0.252]\n",
      ">36, d[0.000,0.000], g[0.058] q[0.228]\n",
      ">37, d[0.001,0.000], g[0.051] q[0.252]\n",
      ">38, d[0.001,0.000], g[0.044] q[0.193]\n",
      ">39, d[0.000,0.000], g[0.045] q[0.180]\n",
      ">40, d[0.000,0.000], g[0.041] q[0.177]\n",
      ">41, d[0.000,0.000], g[0.038] q[0.179]\n",
      ">42, d[0.000,0.000], g[0.039] q[0.156]\n",
      ">43, d[0.000,0.000], g[0.038] q[0.159]\n",
      ">44, d[0.000,0.000], g[0.034] q[0.160]\n",
      ">45, d[0.000,0.000], g[0.033] q[0.138]\n",
      ">46, d[0.000,0.000], g[0.032] q[0.132]\n",
      ">47, d[0.000,0.000], g[0.032] q[0.120]\n",
      ">48, d[0.001,0.000], g[0.032] q[0.111]\n",
      ">49, d[0.000,0.000], g[0.027] q[0.121]\n",
      ">50, d[0.000,0.000], g[0.027] q[0.108]\n",
      ">51, d[0.000,0.000], g[0.028] q[0.106]\n",
      ">52, d[0.001,0.000], g[0.025] q[0.094]\n",
      ">53, d[0.001,0.000], g[0.022] q[0.086]\n",
      ">54, d[0.000,0.000], g[0.024] q[0.099]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-74-ea36598ab7ee>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mgan\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgen_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdiscr_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfogan_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-72-b61202c75d3d>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, gen_model, discr_model, infogan_model, dataset, n_epochs)\u001b[0m\n\u001b[1;32m    189\u001b[0m             \u001b[0;31m#X_real, y_real = generate_real_samples(dataset, half_batch)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m             \u001b[0;31m# update discriminator and q model weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 191\u001b[0;31m             \u001b[0md_loss1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdiscr_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    192\u001b[0m             \u001b[0;31m# generate 'fake' examples\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m             \u001b[0mX_fake\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_fake\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate_fake_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgen_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1098\u001b[0m                 _r=1):\n\u001b[1;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1101\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    853\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    854\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 855\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    856\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    857\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2942\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2943\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2945\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1917\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1918\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1919\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1921\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    558\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    561\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "gan.train(gen_model, discr_model, infogan_model, ds, n_epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
